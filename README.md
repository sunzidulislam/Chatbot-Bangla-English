Certainly! Here's the full polished README.md text incorporating all your content plus the suggested improvements for clarity, formatting, and flow:

````markdown
# ğŸ¤– Bangla-English PDF-Based Retrieval-Augmented Generation (RAG) QA System

This project implements a bilingual chatbot capable of understanding and answering questions from PDF documents written in Bangla and English. It uses advanced retrieval-augmented generation techniques powered by **Google Gemini**, **LangChain**, and **FAISS** to deliver contextually accurate and semantically relevant answers.

---

## ğŸš€ Key Features

* ğŸŒ **Multilingual Support:** Understands and responds in both Bangla ğŸ‡§ğŸ‡© and English ğŸ‡ºğŸ‡¸  
* ğŸ“„ **PDF Content Extraction & Retrieval:** Efficiently parses, cleans, and indexes PDF documents for semantic search  
* ğŸ¤– **Google Gemini-Powered Generation:** Uses Googleâ€™s state-of-the-art LLM models for natural, coherent answer generation  
* âœ… **RAG Evaluation Metrics:** Provides **Cosine Similarity** and **Groundedness** scores to quantify answer relevance and trustworthiness  
* ğŸ§  **Dual Memory Architecture:** Combines FAISS-based long-term semantic vector store with in-session short-term chat history for improved conversational context  

---

## ğŸ“¸ Sample Output Preview

<img width="1056" height="747" alt="Chatbot Sample Screenshot" src="https://github.com/user-attachments/assets/4cb72868-04da-4964-8d6e-283978743bdf" />

<img width="1912" height="883" alt="Chatbot Output with Scores" src="https://github.com/user-attachments/assets/226d0633-dc46-4bad-b589-a851b2b2812e" />

---

## ğŸ”‘ Prerequisites

* Python 3.9 or higher  
* Git installed  
* Google Gemini API key â€” [Request API Key](https://ai.google.dev/)  
  *(Ensure you have access to the Gemini API and have set up billing, if required.)*

---

## ğŸ”§ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/bangla-rag-chatbot.git
cd bangla-rag-chatbot
````

### 2. Create & Activate Virtual Environment

```bash
python -m venv venv
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

<details>
<summary>Or install packages individually</summary>

```bash
pip install streamlit pymupdf langchain faiss-cpu pandas scikit-learn langchain-google-genai numpy
```

</details>

### 4. Run the Application

```bash
python -m streamlit run app.py
```

You can also pass your API key as a command-line argument:

```bash
python -m streamlit run app.py -- --api_key YOUR_GOOGLE_GEMINI_API_KEY
```

---

## ğŸ›  Usage Instructions

1. Input your **Google Gemini API Key** in the sidebar.
2. Upload one or more Bangla or English PDFs (e.g., academic notes, literature).
3. Type questions in either Bangla or English natural language.
4. Receive detailed answers generated by Gemini, along with:

   * **Cosine Similarity Score:** Reflects semantic relevance of retrieved documents
   * **Groundedness Score:** Indicates answer fidelity to the source documents

---

## ğŸ“‹ Project Overview

### Tools, Libraries, and Frameworks

* **Streamlit:** Interactive web interface for ease of use
* **PyMuPDF (fitz):** High-fidelity PDF text extraction handling complex layouts
* **Regex (re):** Robust text cleaning and normalization
* **NumPy:** Efficient vector math for similarity calculations
* **Pandas:** Data management and exporting conversation logs
* **Base64:** Encoding for secure CSV download links
* **LangChain:** Orchestration of LLM pipelines and vector search

  * `RecursiveCharacterTextSplitter` for smart chunking of large texts
  * `GoogleGenerativeAIEmbeddings` for high-quality multilingual semantic embeddings
  * `ChatGoogleGenerativeAI` as the conversational LLM interface
  * `FAISS` for scalable vector similarity search
  * `load_qa_chain` and `PromptTemplate` for flexible, context-aware question answering

### Data Preprocessing & Chunking

* Extracted raw text is cleaned to remove non-breaking spaces and excessive newlines.
* Recursive character-based chunking with a chunk size of 1500 characters and 400 characters overlap maintains semantic integrity and contextual continuity.
* Chunking respects paragraph and sentence boundaries by leveraging multiple separators (newlines, punctuation).

### Embeddings & Vector Store

* Google Gemini's `embedding-001` model was selected for its multilingual capabilities and semantic accuracy in both Bangla and English.
* Embeddings are stored in a local FAISS index for efficient similarity search during query time.

### Question-Answering Pipeline

* Query and document chunks are embedded using the same model to ensure meaningful semantic comparisons.
* Top-k relevant chunks retrieved by FAISS are passed to a custom prompt-based conversational chain using Google Geminiâ€™s chat model (`gemini-2.5-pro`).
* The prompt enforces answer grounding and restricts hallucinations by instructing the model to reply only if supported by context.

---

## ğŸ“Œ Sample Queries and Model Outputs

**Bangla Query:**

> *à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?*

**Answer:**

> à¦ªà§à¦°à¦¦à¦¤à§à¦¤ à¦¤à¦¥à§à¦¯ à¦…à¦¨à§à¦¸à¦¾à¦°à§‡, à¦…à¦¨à§à¦ªà¦®à§‡à¦° **à¦®à¦¾à¦®à¦¾à¦•à§‡** à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤

---

**English Query:**

> *What is the main theme of the document?*

**Answer:**

> The main theme is a comprehensive question bank on Rabindranath Tagore's short story 'Aparichita', covering key characters, plot, and themes.

---

## ğŸ” Evaluation Metrics Explained

* **Cosine Similarity Score:**
  Measures semantic closeness between the query and retrieved chunksâ€™ embeddings. Scores near 1 indicate high relevance.

* **Groundedness Score:**
  Calculates the proportion of answer tokens that appear in the retrieved context, ensuring answers are firmly based on source documents.

---

## â“ Must Answer Questions

### What method or library did you use to extract the text, and why? Did you face any formatting challenges with the PDF content?

* **Method/Library:** Used PyMuPDF (`fitz`) to extract text from PDFs.
* **Why:** PyMuPDF provides precise text extraction with control over page reading and handles various PDF layouts well.
* **Formatting challenges:** Removal of non-breaking spaces (`\xa0`) and normalization of multiple newlines were necessary. Regex was used to clean and strip whitespace, making text uniform and easier to chunk.

---

### What chunking strategy did you choose? Why do you think it works well for semantic retrieval?

* **Strategy:** Character-based chunking with overlaps using `RecursiveCharacterTextSplitter`.
* **Parameters:** Chunk size 1500 characters, overlap 400 characters.
* **Why:** Ensures chunk sizes fit model token limits while overlaps preserve sentence/idea continuity across chunks, improving semantic retrieval accuracy. Logical splitting respects paragraphs and punctuation.

---

### What embedding model did you use? Why? How does it capture meaning?

* **Model:** `GoogleGenerativeAIEmbeddings` with `"models/embedding-001"` from Google Gemini.
* **Why:** Optimized for multilingual (Bangla & English) semantic understanding with high accuracy.
* **How it captures meaning:** Converts text into dense vector representations encoding semantic relationships, allowing similarity calculations beyond exact keyword matches.

---

### How are you comparing the query with your stored chunks? Why this similarity method and storage?

* **Similarity method:** Cosine similarity between query and chunk embeddings.
* **Storage:** Local FAISS vector store for fast nearest neighbor search.
* **Why:** Cosine similarity efficiently measures semantic closeness in embedding space. FAISS is scalable and optimized for vector data retrieval, enabling real-time response.

---

### How do you ensure that questions and document chunks are compared meaningfully? What happens if the query is vague or missing context?

* Using the same embedding model for queries and chunks ensures comparable semantic space.
* Overlapping chunking keeps context intact.
* The question-answer chain's prompt instructs the LLM to answer only when supported by retrieved context, avoiding hallucinations.
* If queries are vague, similarity scores drop, and the system replies that the answer is not in the context, prompting clarification.

---

### Do the results seem relevant? How can they be improved?

* Current approach yields good relevance with overlapping chunking, a strong embedding model, and groundedness checks.
* Improvements include adaptive chunking based on semantic units, domain-specific or newer embedding models, larger document corpora, and reranking strategies using cross-encoders.

---

## ğŸ“ Frequently Asked Questions (FAQs)

1. **How is PDF text extracted and cleaned?**
   PyMuPDF extracts text precisely, while regex cleans unwanted spaces and normalizes line breaks.

2. **What chunking approach is used?**
   Recursive character-based chunking with overlaps preserves meaning and context across chunks.

3. **Why choose the Google Gemini embedding model?**
   It supports multilingual text with high semantic fidelity, suitable for Bangla-English hybrid content.

4. **How are queries matched to documents?**
   Embeddings and cosine similarity search via FAISS enable fast and accurate semantic retrieval.

5. **How does the system handle vague or out-of-context queries?**
   It returns safe fallback answers indicating no relevant information, avoiding hallucinations.

6. **How can system relevance be improved?**
   Adaptive chunking, newer embeddings, larger datasets, and reranking can enhance accuracy.

---

## âš ï¸ Troubleshooting

* **API errors or rate limits:** Check your Google Gemini API quota and key validity.
* **Poor answer relevance:** Upload more comprehensive PDFs or refine your queries.
* **Dependency issues:** Ensure all packages are installed correctly with `pip install -r requirements.txt`.

---

## ğŸ“¦ requirements.txt

```txt
streamlit
pymupdf
langchain
faiss-cpu
pandas
scikit-learn
langchain-google-genai
numpy
```

---

## ğŸ“‚ Data Privacy

Uploaded PDFs and queries are processed locally or securely sent to the Google Gemini API. No data is stored permanently unless saved explicitly by the user.

---

## ğŸ‘¨â€ğŸ’» Author

**Md. Sunzidul Islam**
AI Researcher & Developer
[GitHub Profile](https://github.com/sunzidulislam)

---

## ğŸ“¬ Contact

For questions, feature requests, or issues, please open a GitHub issue or contact via email.

---
