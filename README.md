Certainly! Here's a polished, professional rewrite of your README content, formatted for clarity and impact:

---

# 🤖 Bangla-English PDF-Based RAG QA System

A robust bilingual **Retrieval-Augmented Generation (RAG)** chatbot designed to answer questions from Bangla and English PDF documents. This system integrates **Google Gemini**, **LangChain**, and **FAISS** to deliver precise, context-aware responses.

---

## 🚀 Features

* 🌐 **Multilingual Support:** Bangla 🇧🇩 and English 🇺🇸 queries and documents
* 📄 **PDF-Based Retrieval:** Extract and index content from uploaded PDFs
* 🤖 **Google Gemini-Powered Generation:** State-of-the-art LLM for answer generation
* ✅ **RAG Evaluation:** Includes groundedness and cosine similarity relevance scoring
* 🧠 **Dual Memory Architecture:** Long-term storage with FAISS vector store and short-term chat history


---

## Sample Ouput view
<img width="1056" height="747" alt="Screenshot 2025-07-24 234434" src="https://github.com/user-attachments/assets/4cb72868-04da-4964-8d6e-283978743bdf" />
<img width="1912" height="883" alt="Screenshot 2025-07-24 234401" src="https://github.com/user-attachments/assets/226d0633-dc46-4bad-b589-a851b2b2812e" />


## 🔑 Prerequisites

* Python 3.9 or higher
* Git installed
* Google Gemini API key — [Obtain API Key](https://ai.google.dev/)

---

## 🔧 Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/bangla-rag-chatbot.git
cd bangla-rag-chatbot
```

### 2. Create and Activate Virtual Environment

```bash
python -m venv venv
# On Linux/macOS
source venv/bin/activate
# On Windows
venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

<details>
<summary>Or install packages manually</summary>

```bash
pip install streamlit pymupdf langchain faiss-cpu pandas scikit-learn langchain-google-genai
```

</details>

### 4. Launch the Application

```bash
streamlit run app.py
```

---

## 🛠 Usage Guide

1. Enter your **Google Gemini API Key** in the sidebar.
2. Upload one or more **Bangla or English PDFs** (e.g., *HSC26 Bangla 1st Paper*).
3. Submit your question in either **Bangla or English**.
4. Receive contextually accurate answers generated by Gemini, accompanied by:

   * **Cosine Similarity Score** — measures semantic relevance
   * **Groundedness Score** — measures how well the answer is supported by source text

---

## 📋 Project Overview

### Used Tools, Libraries, and Packages

* **Streamlit:** Web UI framework
* **PyMuPDF (fitz):** Accurate and efficient PDF text extraction
* **re:** Text cleaning and preprocessing
* **numpy:** Vector operations (cosine similarity)
* **pandas:** Data management and export
* **base64:** Encoding for CSV downloads
* **LangChain:** Modular framework for LLM apps

  * `RecursiveCharacterTextSplitter` for intelligent chunking
  * `GoogleGenerativeAIEmbeddings` for semantic embedding generation
  * `ChatGoogleGenerativeAI` for conversational QA chains
  * `FAISS` vector store for efficient similarity search
  * `load_qa_chain` and `PromptTemplate` for QA orchestration

---

### Sample Queries and Outputs

**Bangla:**

> *কাকে অনুপমের ভাগ্য দেবতা বলে উল্লেখ করা হয়েছে?*

> **Output:**
> প্রদত্ত তথ্য অনুসারে, অনুপমের **মামাকে** ভাগ্য দেবতার প্রধান এজেন্ট বলা হয়েছে।

**English:**

> *What is the main theme of the document?*

> **Output:**
>In English: The main theme of the document is a question bank or study guide for Rabindranath Tagore's short story 'Aparichita'. It contains a compilation of multiple-choice questions (MCQs) and their answers concerning the story's characters, events, and central ideas.

---

### Evaluation Metrics

* **Cosine Similarity:** Quantifies semantic closeness between query and retrieved chunks
* **Groundedness Score:** Proportion of answer tokens supported by retrieved context

These metrics provide transparency and reliability indicators for each response.

---

### FAQs

1. **Text Extraction Method & Challenges**

   * Used PyMuPDF for reliable PDF text extraction.
   * Handled formatting issues like non-breaking spaces and excessive newlines using regex-based cleaning.

2. **Chunking Strategy**

   * Character-based chunking with 1500-char chunks and 400-char overlaps via `RecursiveCharacterTextSplitter`.
   * Ensures chunks are semantically coherent and manageable for embedding models.

3. **Embedding Model Choice**

   * Google Gemini’s `embedding-001` model chosen for its strong multilingual semantic understanding.
   * Converts text into meaningful vector representations enabling effective similarity comparisons.

4. **Similarity Comparison & Storage**

   * Utilizes cosine similarity of embeddings for semantic search.
   * Employs FAISS vector store for scalable, efficient nearest neighbor retrieval.

5. **Ensuring Meaningful Query-Context Comparison**

   * Same embedding model for query and context ensures compatible vectors.
   * Overlapping chunks and prompt engineering enforce grounded answer generation.
   * Vague queries yield low similarity and fallback to safe default responses.

6. **Improving Results**

   * Adaptive chunking or semantic segmentation.
   * Exploring newer or domain-specific embedding models.
   * Expanding document corpus for broader knowledge.
   * Incorporating reranking and context window enhancements.

---

## 📦 requirements.txt

```txt
streamlit
pymupdf
langchain
faiss-cpu
pandas
scikit-learn
langchain-google-genai
```

---

## 👨‍💻 Author

**Md. Sunzidul Islam**
AI Researcher & Developer
[GitHub Profile](https://github.com/sunzidulislam)

---

## 📬 Contact

For questions or issues, please open a GitHub issue or contact via email.
