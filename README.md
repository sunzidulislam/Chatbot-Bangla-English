# ğŸ¤– Bangla-English PDF-Based Retrieval-Augmented Generation (RAG) QA System

A sophisticated bilingual **Retrieval-Augmented Generation (RAG)** chatbot tailored for question answering from Bangla and English PDF documents. Leveraging **Google Gemini**, **LangChain**, and **FAISS**, this system delivers context-aware, precise, and multilingual responses, optimized for academic and cultural texts.

---

## ğŸš€ Key Features

* ğŸŒ **Multilingual Support:** Understands and responds in both Bangla ğŸ‡§ğŸ‡© and English ğŸ‡ºğŸ‡¸
* ğŸ“„ **PDF Content Extraction & Retrieval:** Efficiently parses, cleans, and indexes PDF documents for semantic search
* ğŸ¤– **Google Gemini-Powered Generation:** Uses Googleâ€™s state-of-the-art LLM models for natural, coherent answer generation
* âœ… **RAG Evaluation Metrics:** Provides **Cosine Similarity** and **Groundedness** scores to quantify answer relevance and trustworthiness
* ğŸ§  **Dual Memory Architecture:** Combines FAISS-based long-term semantic vector store with in-session short-term chat history for improved conversational context

---

## ğŸ“¸ Sample Output Preview

<img width="1056" height="747" alt="Chatbot Sample Screenshot" src="https://github.com/user-attachments/assets/4cb72868-04da-4964-8d6e-283978743bdf" />

<img width="1912" height="883" alt="Chatbot Output with Scores" src="https://github.com/user-attachments/assets/226d0633-dc46-4bad-b589-a851b2b2812e" />

---

## ğŸ”‘ Prerequisites

* Python 3.9 or higher
* Git installed
* Google Gemini API key â€” [Request API Key](https://ai.google.dev/)

---

## ğŸ”§ Installation & Setup

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/bangla-rag-chatbot.git
cd bangla-rag-chatbot
```

### 2. Create & Activate Virtual Environment

```bash
python -m venv venv
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

<details>
<summary>Or install packages individually</summary>

```bash
pip install streamlit pymupdf langchain faiss-cpu pandas scikit-learn langchain-google-genai
```

</details>

### 4. Run the Application

```bash
python -m streamlit run app.py
```

---

## ğŸ›  Usage Instructions

1. Input your **Google Gemini API Key** in the sidebar.
2. Upload one or more Bangla or English PDFs (e.g., academic notes, literature).
3. Type questions in either Bangla or English natural language.
4. Receive detailed answers generated by Gemini, along with:

   * **Cosine Similarity Score**: Reflects semantic relevance of retrieved documents
   * **Groundedness Score**: Indicates answer fidelity to the source documents

---

## ğŸ“‹ Project Overview

### Tools, Libraries, and Frameworks

* **Streamlit:** Interactive web interface for ease of use
* **PyMuPDF (fitz):** High-fidelity PDF text extraction handling complex layouts
* **Regex (re):** Robust text cleaning and normalization
* **NumPy:** Efficient vector math for similarity calculations
* **Pandas:** Data management and exporting conversation logs
* **Base64:** Encoding for secure CSV download links
* **LangChain:** Orchestration of LLM pipelines and vector search

  * `RecursiveCharacterTextSplitter` for smart chunking of large texts
  * `GoogleGenerativeAIEmbeddings` for high-quality multilingual semantic embeddings
  * `ChatGoogleGenerativeAI` as the conversational LLM interface
  * `FAISS` for scalable vector similarity search
  * `load_qa_chain` and `PromptTemplate` for flexible, context-aware question answering

### Data Preprocessing & Chunking

* Extracted raw text is cleaned to remove non-breaking spaces and excessive newlines.
* Recursive character-based chunking with a chunk size of 1500 characters and 400 characters overlap maintains semantic integrity and contextual continuity.
* Chunking respects paragraph and sentence boundaries by leveraging multiple separators (newlines, punctuation).

### Embeddings & Vector Store

* Google Gemini's `embedding-001` model was selected for its multilingual capabilities and semantic accuracy in both Bangla and English.
* Embeddings are stored in a local FAISS index for efficient similarity search during query time.

### Question-Answering Pipeline

* Query and document chunks are embedded using the same model to ensure meaningful semantic comparisons.
* Top-k relevant chunks retrieved by FAISS are passed to a custom prompt-based conversational chain using Google Geminiâ€™s chat model (`gemini-2.5-pro`).
* The prompt enforces answer grounding and restricts hallucinations by instructing the model to reply only if supported by context.

---

### Sample Queries and Model Outputs

**Bangla Query:**

> *à¦•à¦¾à¦•à§‡ à¦…à¦¨à§à¦ªà¦®à§‡à¦° à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾ à¦¬à¦²à§‡ à¦‰à¦²à§à¦²à§‡à¦– à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡?*

> **Answer:**
> à¦ªà§à¦°à¦¦à¦¤à§à¦¤ à¦¤à¦¥à§à¦¯ à¦…à¦¨à§à¦¸à¦¾à¦°à§‡, à¦…à¦¨à§à¦ªà¦®à§‡à¦° **à¦®à¦¾à¦®à¦¾à¦•à§‡** à¦­à¦¾à¦—à§à¦¯ à¦¦à§‡à¦¬à¦¤à¦¾à¦° à¦ªà§à¦°à¦§à¦¾à¦¨ à¦à¦œà§‡à¦¨à§à¦Ÿ à¦¬à¦²à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤

**English Query:**

> *What is the main theme of the document?*

> **Answer:**
> The main theme is a comprehensive question bank on Rabindranath Tagore's short story 'Aparichita', covering key characters, plot, and themes.

---

### Evaluation Metrics Explained

* **Cosine Similarity Score:**
  Measures semantic closeness between the query and retrieved chunksâ€™ embeddings. Scores near 1 indicate high relevance.

* **Groundedness Score:**
  Calculates the proportion of answer tokens that appear in the retrieved context, ensuring answers are firmly based on source documents.

---

### Frequently Asked Questions (FAQs)

1. **How is PDF text extracted and cleaned?**

   * PyMuPDF is used for precise extraction.
   * Regex cleans and normalizes the text, including removing unwanted spaces and reducing multiple line breaks.

2. **What chunking approach was used and why?**

   * Recursive character-based chunking with overlaps maintains context and respects natural text boundaries.
   * This improves semantic retrieval by preventing loss of meaning across chunk boundaries.

3. **Why was the Google Gemini embedding model chosen?**

   * It supports multilingual input with high semantic fidelity, ideal for Bangla-English hybrid texts.
   * Embeddings effectively represent meaning beyond keyword matching.

4. **How are queries matched to document chunks?**

   * By embedding both with the same model and performing cosine similarity search in FAISS, which is fast and scalable.

5. **How does the system handle vague or out-of-context queries?**

   * Low similarity scores trigger safe fallback answers indicating no relevant information found, avoiding hallucinations.

6. **How can system performance and relevance be improved?**

   * Incorporating adaptive chunking strategies or semantic segmentation.
   * Leveraging newer embedding models or domain-specific fine-tuning.
   * Expanding the document corpus for broader knowledge coverage.
   * Adding reranking or cross-encoder re-ranking layers to refine retrieval precision.

---

## ğŸ“¦ requirements.txt

```txt
streamlit
pymupdf
langchain
faiss-cpu
pandas
scikit-learn
langchain-google-genai
numpy
```

---

## ğŸ‘¨â€ğŸ’» Author

**Md. Sunzidul Islam**

AI Researcher & Developer

[GitHub Profile](https://github.com/sunzidulislam)

---

## ğŸ“¬ Contact

For questions, feature requests, or issues, please open a GitHub issue or reach out via email.
